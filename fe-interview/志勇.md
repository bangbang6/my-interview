#### 2.http请求过程：

1.如果是第一次请求,dns解析拿到ip

2.客户端发送http报文给对应服务器，这个过程要经过应用层，传输层，网络层，数据链路层，物理层对这个报文处理(见ps3)

3.客户端和服务端进行三次握手建立tcp连接

4.服务端返回response给客户端

5.如果是两次以上的请求，浏览器或者服务器会通过http的header参数，判断资源是否过期，没用过期则用缓存，否则去服务器拿新的资源(见ps4)

#### 3.各层对数据报的处理

1.应用层有很多协议比如http,ftp,pop3,浏览器会在应用层，把请求的数据报封装为按照http协议要求的格式，定义一系列请求的head字段，等待运输层接收。

2.运输层主要协议有tcp,udp,运输层拿到数据报之后，会先看是否和目的主机有连接，没有则进行三次握手,建立tcp连接，如果连接成功，会对数据报进一步封装，加上源主机端口号和目的主机端口号，然后给到网络层

3.网络层主要协议有ip协议,接受运输层的数据报，增加目的主机ip，封装成符合ip协议的ip数据报，然后给数据链路层

4.数据链路层有ARP协议，通过ip地址解析为为目的地址的mac地址,通过物理层转发出去，到达目的的局域网后，通过广播被目的主机接收

## 4.浏览器缓存策略

![image-20210603105401046](../../../typora/images/sEBhotPARxgObHU.png)

浏览器先看强缓存再看协商缓存

步骤：

1.当我们输入url，浏览器会去查看自身是否有缓存，如果没有缓存会直接请求服务器获取资源，并缓存到浏览器一份

2.如果浏览器有缓存，此时检查http的请求头，看cache-control、expires字段，判断是否过了缓存的有效期，如果没有过有效期，则返回**200**状态码和对应的缓存数据。

3、如果浏览器缓存已过期，就携带请求头字段`If-None-Match`和`If-Modified-Since`去服务器拉取资源，服务器看到这两个字段，发现和当前服务器资源一致，就直接返回缓存和状态码**304**。服务器一般会先验证`If-None-Match/ETag`，如果不变，再去验证`If-Modified-Since/Last-Modified`

即强制缓存是在浏览器端来判断的缓存，协商缓存是服务器来判断的缓存

#### 1.强缓存

主要看http头的两个字段 expires , cache-control

**expires**是http1.0的定义，返回一个绝对的时间GMT，为过期时间。这就导致如果服务器时间和浏览器时间不一致，可能会使缓存失效。

**cache-control**是http1.1的定义，可以定义的值有

max-age=600 表示最长有效期为600s

no-cache 不走**浏览器缓存**，每次都去浏览器协商缓存

no-store 每次都请求服务器最新的资源(即也不判断浏览器缓存 也不走协商缓存 直接拿新资源)

private 私有，只能在用户终端缓存，不能在cdn或中间的服务器或者代理服务器缓存

public 公有，可以在所有节点缓存

两者同时存在则cache-control优先级高

#### 2.协商缓存

看If-Modified-Since`就是之前返回的`Last-Modified`，`If-None-Match`就是之前返回的`ETag

## 5.cdn节点

客户端到服务器之间可能存在代理服务器或者cdn节点，相当于增加了一个缓存节点，cdn会判断是否过期，然后返回新资源

CDN的存在解决了跨地域请求的时延问题；对服务器压力进行了分流。

四次挥手：如果请求结束，服务器和客户端进行四次握手，断开连接。

## 6.dns解析

递归查询:都是由本地dns服务器去发出请求，顺序由根->顶级->二级  最终返回一个结果给客户端



迭代查询  客户端自己一个一个去请求 根->顶级->二级服务器 有多个返回结果给客户端

## 7.如何设置缓存

通过node设置header 或者ngnix设置

```js
res.setHeader('max-age': '3600 public')  //强制缓存
res.setHeader(etag: '5c20abbd-e2e8')  //协商缓存
res.setHeader('last-modified': Mon, 24 Dec 2018 09:49:49 GMT)
```

ngnix:设置全部都要最新

![image-20210603112150156](../../../typora/images/yU2FnQpawYzDsZo.png)

## 8.三次握手和四次挥手

#### 1.三次握手:

![image-20210603112706920](../../../typora/images/HcaByiDA1LxWXJf.png)



**<1> 第一次握手**

Client将标志位SYN置为1，随机产生一个值seq=x，并将该数据包发送给Server，Client进入SYN_SENT状态，等待Server确认。

**<2> 第二次握手**

Server收到数据包后由标志位SYN=1知道Client请求建立连接，Server将标志位SYN和ACK都置为1，ack=x+1，随机产生一个值seq=y，并将该数据包发送给Client以确认连接请求，Server进入SYN_RCVD状态。

**<3> 第三次握手**

Client收到确认后，检查ack是否为x+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=y+1，并将该数据包发送给Server，Server检查ack是否为y+1，ACK是否为1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了。

**补充1**：ack=x+1是指之前的x报文段我都收到了，ACK=1是指确定收到(acknowledgement 确认) syn=1是指请求发起连接 一边发一个请求发起连接即可，只用建立一个连接

**补充2：SYN攻击**

在三次握手过程中，Server发送SYN-ACK之后，收到Client的ACK之前的TCP连接称为半连接（half-open connect），此时Server处于SYN_RCVD状态，当收到ACK后，Server转入ESTABLISHED状态(这个ACK=1表示客户端收到服务端发送的SYN-ACK）。SYN攻击就是Client在短时间内伪造大量不存在的源IP地址，并向Server不断地发送SYN包，Server回复确认包，并等待Client的确认，由于源地址是不存在的，因此，Server需要不断重发直至超时，这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络堵塞甚至系统瘫痪。SYN攻击是一种典型的DDOS攻击，检测SYN攻击的方式非常简单，即当Server上有大量半连接状态且源IP地址是随机的，则可以断定遭到SYN攻击了，使用如下命令可以让之现行：netstat -nap | grep SYN_RECV

**补充3:为什么不能两次握手**

1.TCP的三次握手过程：主机A向B发送连接请求；主机B对收到的主机A的报文段进行确认；主机A再次对主机B的确认进行确认。

2.采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输后然后关闭连接。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。如果只有两次握手，那么B就以为成功建立啦连接，然后等待，如果是三次，那么B此时只是半连接状态，没收到A的第三次的确认就知道关闭

#### 2.四次挥手

![image-20210603113940151](../../../typora/images/Oib1auQ9hqMoUNw.png)

**<1> 第一次挥手**

Client发送一个FIN，用来关闭Client到Server的数据传送，Client进入FIN_WAIT_1状态。

**<2> 第二次挥手**

Server收到FIN后，发送一个ACK给Client，确认序号为收到序号+1（与SYN相同，一个FIN占用一个序号），Server进入CLOSE_WAIT状态。

**<3> 第三次挥手**

Server发送一个FIN，用来关闭Server到Client的数据传送，Server进入LAST_ACK状态。

**<4> 第四次挥手**

Client收到FIN后，Client进入TIME_WAIT状态，接着发送一个ACK给Server，确认序号为收到序号+1，Server进入CLOSED状态，完成四

**补充：**

**1. 为什么连接的时候是三次握手，关闭的时候却是四次挥手？**

答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。（即因为服务端还有数据没发送完，所以不能和ACK=1一起发送FIN=1)(FIN=1即发起关闭连接)

**2. 为什么TIME_WAIT状态需要经过2MSL（maximum Segment Lifetime）(最大报文段生存时间)才能返回到CLOSE状态？**

答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。(即可能客户端发送给服务端的最后一个ACK=1即确定收到服务端关闭的报文丢失，如果不重发这个报文，那么服务端就会一直等待浪费资源)

## 10.http和https

**一、HTTP和HTTPS的基本概念**

　　HTTP：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。

　　HTTPS：是以安全为目标的HTTP通道，简单讲是HTTP的安全版，即HTTP下加入SSL层，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。

　　HTTPS协议的主要作用可以分为两种：一种是建立一个信息安全通道，来保证数据传输的安全；另一种就是确认网站的真实性。

**二、HTTP与HTTPS有什么区别？**

　　HTTP协议传输的数据都是**未加密**的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行**加密传输**、**身份认证**的网络协议，要比http协议安全。

　　HTTPS和HTTP的区别主要如下：

　　1、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

　　2、http是超文本传输协议，信息是明文传输，https则是具有安全性的ssl加密传输协议。

　　3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

　　4、http的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比http协议安全。

**三、HTTPS的缺点**

　　虽然说HTTPS有很大的优势，但其相对来说，还是存在不足之处的：

　　（1）HTTPS协议**握手阶段比较费时**，会使页面的加载时间延长近50%，增加10%到20%的耗电；

　　（2）HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗，甚至已有的安全措施也会因此而受到影响；

　　（3）SSL**证书需要钱**，功能越强大的证书费用越高，个人网站、小网站没有必要一般不会用。

　  （4）SSL证书通常需要绑定IP，不能在同一IP上绑定多个域名，IPv4资源不可能支撑这个消耗。

　　（5）HTTPS协议的加密范围也比较有限，在黑客攻击、拒绝服务攻击、服务器劫持等方面几乎起不到什么作用。最关键的，SSL证书的信用链体系并不安全，特别是在某些国家可以控制CA根证书的情况下，中间人攻击一样可行。

**HTTP 缺点**

- 无状态，有时候，需要保存信息，比如像购物系统，需要保留下顾客信息等等，另外一方面，有时候，无状态也会减少网络开销，比如类似直播行业这样子等，这个还是分场景来说。
- 明文传输，即协议里的报文(主要指的是头部)不使用二进制数据，而是文本形式。这让HTTP的报文信息暴露给了外界，给攻击者带来了便利。
- 队头阻塞，当http开启长连接时，共用一个TCP连接，当某个请求时间过长时，其他的请求只能处于阻塞状态，这就是队头阻塞问题。

### 8 说一说HTTP 的请求方法

- HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法
- HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT

http/1.1规定了以下请求方法(注意，都是大写):

- GET： 请求获取Request-URI所标识的资源
- POST： 在Request-URI所标识的资源后附加新的数据
- HEAD： 请求获取由Request-URI所标识的资源的**响应消息报头**
- PUT： 请求服务器存储一个资源，并用Request-URI作为其标识（修改数据）
- DELETE： 请求服务器删除对应所标识的资源
- TRACE： 请求服务器回送收到的请求信息，主要用于**测试或诊断**
- CONNECT： **建立连接隧道，用于代理服务器**
- OPTIONS： 列出可对资源实行的**请求方法**，用来跨域请求
- JS 的 XMLHttpRequest对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。

### 9 谈一谈GET 和 POST 的区别

本质上，只是语义上的区别，GET 用于获取资源，POST 用于提交资源。

具体差别👇

- 从缓存角度看，GET 请求后**浏览器会主动缓存**，POST 默认情况下不能。
- 从参数角度来看，GET请求一般放在URL中，因此不安全，POST请求放在请求体中，相对而言较为安全，但是在抓包的情况下都是一样的。
- 从编码角度看，GET请求只能经行URL编码，**只能接受ASCII码**，而POST支持更多的**编码类型**且不对数据类型限值。
- GET请求幂等，POST请求不幂等，幂等指发送 M 和 N 次请求（两者不相同且都大于1），服务器上资源的状态一致。
- GET请求会一次性发送请求报文，POST请求通常分为**两个TCP数据包**，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分

### 10 谈一谈队头阻塞问题

什么是队头阻塞？

对于每一个HTTP请求而言，这些任务是会被放入一个**任务队列**中**串行执行**的，一旦队首任务请求太慢时，就会阻塞后面的请求处理，这就是HTTP队头阻塞问题。

**有什么解决办法吗** 都是增加多个任务队列

并发连接

我们知道对于一个域名而言，是允许分配多个长连接的，那么可以理解成增加了任务队列，也就是说不会导致一个任务阻塞了该任务队列的其他任务，在RFC规范中规定客户端最多并发2个连接，不过实际情况就是要比这个还要多，举个例子，Chrome中是6个。

域名分片

- 顾名思义，我们可以在一个域名下分出多个**二级域名**出来，而它们最终指向的还是同一个**服务器**，这样子的话就可以并发处理的任务队列更多，也更好的解决了队头阻塞的问题。
- 举个例子，比如TianTian.com，可以分出很多二级域名，比如Day1.TianTian.com，Day2.TianTian.com,Day3.TianTian.com,这样子就可以有效解决队头阻塞问题。

**11 谈一谈HTTP数据传输**

大概遇到的情况就分为定长数据 与 不定长数据的处理吧。

定长数据

对于定长的数据包而言，发送端在发送数据的过程中，需要设置Content-Length,来指明发送数据的长度。

当然了如果采用了Gzip压缩的话，Content-Length设置的就是压缩后的传输长度

- Content-Length如果存在并且有效的话，则必须和消息内容的传输长度完全一致，也就是说，如果过短就会截断，过长的话，就会导致超时。
- 在HTTP/1.1版本中，如果是Keep-alive的话，chunked优先级高于Content-Length

**不定长数据**



```
Transfer-Encoding: chunked
```

通过chunked机制，可以完成对不定长数据的处理，当然了，你需要知道的是

- 如果头部信息中有Transfer-Encoding,优先采用Transfer-Encoding里面的方法来找到对应的长度。
- 如果设置了Transfer-Encoding，那么Content-Length将被忽视。
- 使用长连接的话，会持续的推送动态内容。

### 13 介绍一下HTTPS和HTTP区别

HTTP + TLS/SSL

SSL

安全套接层（Secure Sockets Layer）

TLS

（传输层安全，Transport Layer Security）

![img](../../../typora/images/a5LqH7VGKQRbStr.png)

- HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。
- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO,谷歌、百度优先索引HTTPS网页。
- HTTPS标准端口443，HTTP标准端口80。
- HTTPS需要用到SSL证书，而HTTP不用。

我觉得记住以下两点HTTPS**主要作用**就行👇

1. 对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全;
2. 对网站服务器进行真实身份认证。

### 14 HTTPS握手过程

- 第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法
- 第二步，服务端确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数
- 第三步，客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务端
- 第四步，服务端使用自己的私钥，获取客户端发来的随机数（即Premaster secret）。
- 第五步，客户端和服务端根据约定的加密方法，使用前面的三个随机数，生成"对话密钥"（session key），用来加密接下来的整个对话过程

总结 随机数 公钥加密随机数 三个随机数加密文件

TLS/SSL 的功能实现主要依赖于三类基本算法：散列函数 、对称加密和非对称加密，其利用**非对称加密实现身份认证和密钥协商(随机数的产生)**，对称加密算法采用协商的密钥对**数据加密**，基于散列函数验证信息的完整性。

**1. 对称加密**

加密和解密用同一个秘钥的加密方式叫做对称加密，所以数据加密得对称加密

问题一: WWW万维网有许许多多的客户端，**不可能都用秘钥A**进行信息加密，这样子很不合理，所以解决办法就是使用一个客户端使用一个密钥进行加密。

问题二:既然不同的客户端使用**不同的密钥**，那么对称加密的**密钥如何传输**？ 那么解决的办法只能是一端生成一个秘钥，然后通过HTTP传输给另一端，那么这样子又会产生新的问题。

问题三: 这个传输密钥的过程，又如何保证加密？如果被中间人拦截，**密钥也会被获取**, 那么你会说对密钥再进行加密，那又怎么保存对密钥加密的过程，是加密的过程？

到这里，我们似乎想明白了，使用对称加密的方式，行不通，所以我们需要采用非对称加密

**2. 非对称加密**





### 谈一谈你对HTTP/2理解



- 提升访问速度(可以对于，请求资源所需时间更少，访问速度更快，相比 http1.0)
- 允许多路复用:多路复用允许同时通过单一的 HTTP/2 连接发送多重请求-响应信息。改 善了:在 http1.1 中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量限 制(连接数量)，超过限制会被阻塞
- 二进制分帧:HTTP2.0 会将所有的传输信息分割为更小的信息或者帧，并对他们进行二 进制编码
- 首部压缩
- 服务器端推送

**头部压缩**

HTTP 1.1版本会出现 User-Agent、Cookie、Accept、Server、Range 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。

HTTP 2.0 使用 HPACK 算法进行压

**多路复用**

- HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制。

HTTP2中：

- 同域名下所有通信都在单个连接上完成

http1.x是改善啦每一次都得用http链接 但是请求还是穿行的 http2改善的是请求也是流水线一样并行的

**二进制分帧**

之前是明文传输，不方便计算机解析，对于回车换行符来说到底是内容还是分隔符，都需要内部状态机去识别，这样子效率低，HTTP/2采用二进制格式，全部传输01串，便于机器解码。

这样子一个报文格式就被拆分为一个个二进制帧，用Headers帧存放头部字段，Data帧存放请求体数据。这样子的话，**就是一堆乱序的二进制帧，它们不存在先后关系**，因此不需要排队等待，解决了HTTP队头阻塞问题。在链路上随机传输 最后根据id组装

在客户端与服务器之间，双方都可以互相发送二进制帧，这样子双向传输的序列，称为流，所以HTTP/2中以流来表示一个TCP连接上进行多个数据帧的通信，这就是多路复用概念。

那乱序的二进制帧，是如何组装成对于的报文呢？

- 所谓的乱序，值的是不同ID的Stream是乱序的，对于同一个Stream ID的帧是按顺序传输的。
- 接收方收到二进制帧后，**将相同的Stream ID组装成完整的请求报文和响应报文**。
- 二进制帧中有一些字段，控制着优先级和流量控制等功能，这样子的话，就可以设置数据帧的优先级，让服务器处理重要资源，优化用户体验。

**tcp缺点**

- TCP 以及 TCP+TLS建立连接的延时,HTTP/2使用TCP协议来传输的，而如果使用HTTPS的话，还需要使用TLS协议进行安全传输，而使用TLS也需要一个握手过程,在传输数据之前，导致我们需要花掉 3～4 个 RTT。
- TCP的队头阻塞并没有彻底解决。在HTTP/2中，多个请求是跑在一个TCP管道中的。但当HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求。

即建立链接时间长；队头阻塞

**18 HTTP3**

基于 **UDP** 协议的“QUIC”协议，让HTTP跑在QUIC上而不是TCP上。主要特性如下

- 实现了类似TCP的流量控制、传输可靠性的功能。虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些TCP中存在的特性
- 实现了快速握手功能。由于QUIC是基于UDP的，所以QUIC可以实现使用0-RTT或者1-RTT来建立连接，解决tcp需要多个rtt来建立链接的问题
- 多路复用，彻底解决TCP中队头阻塞的问题。

**总结http**

- HTTP 0.9：1991年,原型版本，功能简陋，只有一个命令GET,只支持纯文本内容，该版本已过时。
- HTTP 1.0
  - 任何格式的内容都可以发送，这使得互联网不仅可以传输文字，还能传输图像、视频、二进制等文件。
  - 除了**GET命令，还引入了POST命令和HEAD命令**。
  - http请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。
  - 只使用 header **中的 If-Modified-Since 和 Expires 作**为缓存失效的标准。
  - 不支持断点续传，也就是说，每次都会传送全部的页面和数据。
  - 通常每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）
- HTTP 1.1 http1.1是目前最为主流的http协议版本，从1999年发布至今，仍是主流的http协议版本。
  - 引入了持久连接（ persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明**Connection: keep-alive**。长连接的连接时长可以通过请求头中的 keep-alive 来设置
  - 引入了管道机制（ pipelining），即在同一个TCP连接里，客户端可以同时发送多个 请求，进一步改进了HTTP协议的效率。
  - HTTP 1.1 中新增加了 **E-tag，If-Unmodified-Since, If-Match, If-None-Match** 等缓存控制标头来控制缓存失效。
  - 支持断点续传，通过使用请求头中的 Range 来实现。
  - 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。
  - 新增方法：**PUT、 PATCH、 OPTIONS、 DELETE。**
- http1.x版本问题
  - 在传输数据过程中，所有内容都**是明文**，客户端和服务器端都无法验证对方的身份，无法保证数据的安全性。
  - HTTP/1.1 版本默认允许复用TCP连接，但是在同一个TCP连接里，所有数据通信是按次序进行的，服务器通常在处理完一个回应后，才会继续去处理下一个，这样子就会造成**队头阻塞**。
  - http/1.x 版本支持Keep-alive，用此方案来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，Keep-alive会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。
- HTTP 2.0
  - 二进制分帧 这是一次彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"：头信息帧和数据帧。
  - 头部压缩 HTTP 1.1版本会出现 User-Agent、Cookie、Accept、Server、Range 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 HPACK 算法进行压缩。
  - 多路复用 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题。
  - 服务器推送 允许服务器未经请求，主动向客户端发送资源，即服务器推送。
  - 请求优先级 可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。

**dns缓存**

- 本地客户端向服务器发起请求查询 IP 地址
- 查看浏览器有没有该域名的 IP 缓存
- 查看操作系统有没有该域名的 IP 缓存
- 查看 Host 文件有没有该域名的解析配置
- 本地dns服务器有没有缓存

缓存也很好理解，在一个请求中，当某个DNS服务器收到一个DNS回答后，它能够回答中的信息缓存在本地存储器中。返回的资源记录中的 TTL 代表了该条记录的缓存的时间。

**DNS实现负载平衡**



原因： 这是因为一般的大型网站使用多台服务器提供服务，**因此一个域名可能会对应 多个服务器地址。**

举个例子来说👇

- 当用户发起网站域名的 DNS 请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合
- 在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。
- 以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。

**DNS 为什么使用 UDP 协议作为传输层协议？**

DNS 使用 UDP 协议作为传输层协议的主要原因是为了避免使用 TCP 协议时造成的**连接时延**

- 为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢。
- 大多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长

**查询过程**，本地查询是递归查询，依次通过浏览器缓存 —>> 本地hosts文件 —>> 本地DNS解析器 —>>本地DNS服务器 —>> 其他域名服务器请求。 **既有本地dns解析器又有服务器**