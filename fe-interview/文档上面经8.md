## **1.浏览器架构**

以前

![img](https://i.loli.net/2021/07/20/wFXmAOK19nk5GMl.png)

现在

![img](https://i.loli.net/2021/07/20/KOLdfhoSpUtZPzB.png)

- 由于进程是相互隔离的，所以当一个页面或者插件崩溃时，影响到的仅仅是当前的页面进程或者插件进程，并不会影响到浏览器和其他页面，这就完美地解决了页面或者插件的崩溃会导致整个浏览器崩溃，也就是不稳定的问题
- JavaScript也是运行在渲染进程中的，所以即使JavaScript阻塞了渲染进程，影响到的也只是当前的渲染页面，而并不会影响浏览器和其他页面，因为其他页面的脚本是运行在它们自己的渲染进程中的

- 插件进程。主要是负责插件的运行，因插件易崩溃，所以需要通过插件进程来隔离，以保证插件进程崩溃不会对浏览器和页面造成影响

\3. 浏览器是多进程的优点

- 默认新开 一个 tab 页面 新建 一个进程,所以单个 tab 页面崩溃不会影响到整个浏览器。
- 第三方插件崩溃也不会影响到整个浏览器。
- 多进程可以充分利用现代 CPU 多核的优势。
- 方便使用沙盒模型隔离插件等进程,提高浏览器的稳定性。

### 2 JavaScript单线程模型

\1. 为什么JavaScript是单线程的呢?

- 这主要与JavaScript用途有关。它的主要用途是与用户互动，以及操作DOM。如果JavaScript是多线程的，会带来很多复杂的问题，假如 JavaScript有A和B两个线程，A线程在DOM节点上添加了内容，B线程删除了这个节点，应该是哪个为准呢? 所以，为了避免复杂性，所以设计成了单线程
- 虽然 HTML5 提出了Web Worker标准。Web Worker 的作用，就是为 JavaScript 创造多线程环境，允许主线程创建 Worker 线程，将一些任务分配给后者运行。但是子线程完全受主线程控制，且不得操作DOM。所以这个并没有改变JavaScript单线程的本质。一般使用 Web Worker 的场景是代码中有很多计算密集型或高延迟的任务，可以考虑分配给 Worker 线程。

\2. 浏览器内核中线程之间的关系(是线程不是进程)

- GUI渲染线程和JS引擎线程互斥
  - js是可以操作DOM的，如果在修改这些元素的同时渲染页面（js线程和ui线程同时运行），那么渲染线程前后获得的元素数据可能就不一致了。
- JS阻塞页面加载
  - js如果执行时间过长就会阻塞页面，因为js和渲染线程不是同时进行的是窜行的

**3.进程（process）和线程（thread）是操作系统的基本概念**。

- 进程是 CPU **资源**分配的最小单位（是能**拥有资源**和独立运行的最小单位）。
- 线程是 CPU **调度**的最小单位（是建立在进程基础上的一次程序**运行**单位）

**4.最新的 Chrome 浏览器包括**：

1 个浏览器（Browser）主进程、1 个 GPU 进程、1 个网络（NetWork）进程、多个渲染进程和多个插件进程。

**3.1 Load 和 DOMContentLoaded 区别**

- Load 事件触发代表页面中的 DOM，CSS，JS，图片已经全部加载完毕。
- DOMContentLoaded 事件触发代表初始的 HTML 被完全加载和解析，不需要等待 CSS，JS，图片加载

**3.2 图层**

一般来说，可以把普通文档流看成一个图层。特定的属性可以生成一个新的图层。不同的图层渲染互不影响，所以对于某些频繁需要渲染的建议单独生成一个新图层，提高性能。但也不能生成过多的图层，会引起反作用。

通过以下几个常用属性可以生成新图层

- 3D 变换：translate3d、translateZ
- will-change
- video、iframe 标签
- 通过动画实现的 opacity 动画转换
- position: fixed

**3.4 常见引起回流属性和方法**

任何会改变元素几何信息(元素的位置和尺寸大小)的操作，都会触发重排，下面列一些栗子

- 添加或者删除可见的DOM元素；
- 元素尺寸改变——边距、填充、边框、宽度和高度
- 内容变化，比如用户在input框中输入文字
- 浏览器窗口尺寸改变——resize事件发生时
- 计算 offsetWidth 和 offsetHeight 属性
- 设置 style 属性的值

**3.1 Cache-Control**

- no-cache：不使用本地缓存。需要使用缓存协商，先与服务器确认返回的响应是否被更改，如果之前的响应中存在ETag，那么请求的时候会与服务端验证，如果资源未被更改，则可以避免重新下载

- no-store：直接禁止游览器缓存数据，每次用户请求该资源，都会向服务器发送一个请求，每次都会下载完整的资源
- public：可以被所有的用户缓存，包括终端用户和CDN等中间代理服务器。
- private：只能被终端用户的浏览器缓存，不允许CDN等中继缓存服务器对其缓存。
- max-age：从当前请求开始，允许获取的响应被重用的最长时间（秒）。
- must-revalidate，当缓存过期时，需要去服务端校验缓存的有效性。

**对于** **cookie****，我们还需要注意安全性**

| 属性      | 作用                                                         |
| --------- | ------------------------------------------------------------ |
| value     | 如果用于保存用户登录态，应该将该值加密，不能使用明文的用户标识 |
| http-only | 不能通过 JS访问 Cookie，减少 XSS攻击                         |
| secure    | 只能在协议为 HTTPS 的请求中携带                              |
| same-site | 规定浏览器不能在跨域请求中携带 Cookie，减少 CSRF 攻击        |

![img](https://i.loli.net/2021/07/20/Qol4XcgafnL3kUN.png)

- Http 字段，即 Cookie 的 httponly 属性。若此属性为 true，则只有在 HTTP Headers 中会带有此 Cookie 的信息，而不能通过 document.cookie 来访问此 Cookie。
- Secure，即该 Cookie 是否仅被使用安全协议传输。安全协议。安全协议有 HTTPS、SSL 等，在网络上传输数据之前先将数据加密。默认为 false。

### 7 跨域方案

很多种方法，但万变不离其宗，都是为了搞定同源策略。重用的有 jsonp、iframe、cors、img、HTML5 postMessage等等。其中用到 html **标签**进行跨域的原理就是 html 标签不受同源策略影响。但只是接受 Get 的请求方式，这个得清楚。

### 8 XSS 和 CSRF

- XSS 简单点来说，就是攻击者想尽一切办法将可以执行的代码注入到网页中。
- 但是总体上我认为分为两类：持久型和非持久型。
- 持久型也就是攻击的代码被服务端写入进数据库中，这种攻击危害性很大，因为如果网站访问量很大的话，就会导致大量正常访问页面的用户都受到攻击。

举个例子，对于评论功能来说，就得防范持久型 XSS 攻击，因为我可以在评论中输入以下内容

![img](https://i.loli.net/2021/07/20/faNLHd51FTDWlJr.png)



- 这种情况如果前后端没有做好防御的话，这段评论就会被存储到数据库中，这样每个打开该页面的用户都会被攻击到。
- 非持久型相比于前者危害就小的多了，一般通过修改 URL 参数的方式加入攻击代码，诱导用户访问链接从而进行攻击。
- 举个例子，如果页面需要从 URL 中获取某些参数作为内容的话，不经过过滤就会导致攻击代码被执行，但是对于这种攻击方式来说，如果用户使用 Chrome 这类浏览器的话，浏览器就能自动帮助用户防御攻击



```
<!-- http://www.domain.com?name=<script>alert(1)</script> -->
<div>{{name}}</div>    
```

解决方法 

1. 转义字符

通过转义可以将攻击代码 <script>alert(1)</script> 变成

```
// -> &lt;script&gt;alert(1)&lt;&#x2F;script&gt;
escape('<script>alert(1)</script>')
```

然后存储到数据库

但是对于显示富文本来说，显然不能通过上面的办法来转义所有字符，因为这样会把需要的格式也过滤掉。对于这种情况，通常采用白名单过滤的办法。

```
const xss = require('xss')
let html = xss('<h1 id="title">XSS Demo</h1><script>alert("xss");</script>')
// -> <h1>XSS Demo</h1>&lt;script&gt;alert("xss");&lt;/script&gt;
```

**2 CSRF**

CSRF 就是利用用户的登录态发起恶意请求

如何防御

- Get 请求不对数据进行修改
- 不让第三方网站访问到用户 Cookie
- 阻止第三方网站请求接口
- 请求时附带验证信息，比如**验证码**或者 token人机验证
- SameSite Cookies: 只能当前域名的网站发出的http请求，携带这个Cookie。当然，由于这是新的cookie属性，在兼容性上肯定会有问题

CSRF攻击，仅仅是利用了http携带cookie的特性进行攻击的，但是攻击站点还是无法得到被攻击站点的cookie。这个和XSS不同，XSS是直接通过拿到Cookie等信息进行攻击的

### 9 Service Worker

Service workers 本质上充当Web应用程序与浏览器之间的代理服务器，也可以在网络可用时作为浏览器和网络间的代理。它们旨在（除其他之外）使得能够创建有效的离线体验，拦截网络请求并基于网络是否可用以及更新的资源是否驻留在服务器上来采取适当的动作

- 在 ServiceWorker 中无法直接访问 DOM，但可以通过 postMessage 接口发送的消息来与其控制的页面进行通信
- ServiceWorker 只能在本地环境下或 HTTPS 网站中使用

目前该技术通常用来做**缓存文件**，提高首屏速度



```
// index.js
if (navigator.serviceWorker) {
  navigator.serviceWorker
    .register("sw.js")
    .then(function(registration) {
      console.log("service worker 注册成功");
    })
    .catch(function(err) {
      console.log("servcie worker 注册失败");
    });
}
// sw.js
// 监听 `install` 事件，回调中缓存所需文件
self.addEventListener("install", e => {
  e.waitUntil(
    caches.open("my-cache").then(function(cache) {
      return cache.addAll(["./index.html", "./index.js"]);
    })
  );
});

// 拦截所有请求事件
// 如果缓存中已经有请求的数据就直接用缓存，否则去请求数据
self.addEventListener("fetch", e => {
  e.respondWith(
    caches.match(e.request).then(function(response) {
      if (response) {
        return response;
      }
      console.log("fetch source");
    })
  );
});
```

给 js 脚本添加 defer 属性，这个属性会让脚本的加载与文档的解析同步解析，然后在**文档解析完成后再执行这个脚本文件**,多个设置了 defer 属性的脚本按规范来说最后是顺序执行的，

给 js 脚本添加 async属性，这个属性会使脚本异步加载，不会阻塞页面的解析过程，但是**当脚本加载完成后立即执行 js脚本**，这个时候如果文档没有解析完成的话同样会阻塞。多个 async 属性的脚本的执行顺序是不可预测的

**DNS解析过程 本地dns服务器包括浏览器缓存 本地hosts文件 本地dns解析器缓存**

![img](https://i.loli.net/2021/08/10/dNLlJ9ktByn78OZ.png)

DNS存在着多级缓存，从离浏览器的距离排序的话，有以下几种: 浏览器缓存，系统缓存，路由器缓存，IPS服务器缓存，根域名服务器缓存，顶级域名服务器缓存，主域名服务器缓存

### 14 定时器与requestAnimationFrame、requestIdleCallback

 setTimeout

setTimeout的运行机制：执行该语句时，是立即把当前定时器代码推入事件队列，当定时器在事件列表中满足设置的时间值时将传入的函数加入任务队列，之后的执行就交给任务队列负责。但是如果此时任务队列不为空，则需等待，所以执行定时器内代码的时间可能会大于设置的

**3. setInterval存在的一些问题：**

JavaScript中使用 setInterval 开启轮询。定时器代码可能在代码再次被添加到队列之前还没有完成执行，结果导致定时器代码连续运行好几次，而之间没有任何停顿。而javascript引擎对这个问题的解决是：当使用setInterval()时，仅当没有该定时器的任何其他代码实例时，才将定时器代码添加到队列中。这确保了定时器代码加入到队列中的最小时间间隔为指定间隔。

![img](https://i.loli.net/2021/07/20/WmpUGQ9rCkNzyHV.png)

此时405的定时器代码还在队列中 为什么405的不执行 因为205的要执行300ms还在执行 405要等单线程的执行完 605发现405还在队列中 605就不会加入啦 而是等900的加入队列(因为405的要从600-900时间执行)

**60fps****与设备刷新率**

卡顿：其中每个帧的预算时间仅比16毫秒多一点（1秒/ 60 = 16.6毫秒）。但实际上，浏览器有整理工作要做，因此您的所有工作是需要在10毫秒内完成。如果无法符合此预算，帧率将下降，并且内容会在屏幕上抖动。此现象通常称为卡顿，会对用户体验产生负面影响。 --- 16ms内浏览器时间被js挤掉了 没时间相应用户请求

跳帧: 假如动画切换在 16ms, 32ms, 48ms时分别切换，跳帧就是假如到了32ms，其他任务还未执行完成，没有去执行动画切帧，等到开始进行动画的切帧，已经到了该执行48ms的切帧。就好比你玩游戏的时候卡了，过了一会，你再看画面，它不会停留你卡的地方，或者这时你的角色已经挂掉了。必须在下一帧开始之前就已经绘制完毕; -- 有一针没执行但是到了下一针的时间就直接执行下一针的任务

**性能**

### 1 DNS 预解析

- DNS 解析也是需要时间的，可以通过预解析的方式来预先获得域名所对应的 IP



```
<link rel="dns-prefetch" href="//blog.poetries.top">
```

**2.强缓存**

实现强缓存可以通过两种响应头实现：Expires和 Cache-Control 。强缓存表示在缓存期间不需要请求，state code为 **200**

**协商缓存**

- 如果缓存过期了，我们就可以使用协商缓存来解决问题。协商缓存需要请求，如果缓存有效会返回 **304**

- 对于某些不需要缓存的资源，可以使用 Cache-control: no-store ，表示该资源不需要缓存
- 对于频繁变动的资源，可以使用 Cache-Control: no-cache 并配合 ETag 使用，表示该资源已被缓存，但是每次都会发送请求询问资源是否更新。
- no-store直接不过问缓存 no-cache是问协商缓存 不问强制缓存

**4 预加载**

- 在开发中，可能会遇到这样的情况。有些资源不需要马上用到，但是希望尽早获取，这时候就可以使用预加载
- 预加载其实是声明式的 fetch ，强制浏览器请求资源，并且不会阻塞 onload 事件，可以使用以下代码开启预加载，唯一缺点就是兼容性不好

```
<link rel="preload" href="http://example.com">
```

总结

- defer 和 async在网络读取的过程中都是异步解析
- defer是有顺序依赖的，async只要脚本加载完后就会执行
- preload 可以对当前页面所需的脚本、样式等资源进行**预加载**
- prefetch 加载的资源一般**不是用于当前页面的**，是未来很可能用到的这样一些资源

**CDN**

静态资源尽量使用 CDN 加载，由于浏览器对于单个域名有并发请求上限，可以考虑使用多个 CDN 域名。对于 CDN 加载静态资源需要注意 CDN 域名要与主站不同，否则

每次请求都会带上主站的 Cookie

**performance提供的timing api 以及几个关键节点**

![img](https://i.loli.net/2021/07/20/lkwUX96bgMq2JFL.png)

```
window.onload = function(){
    setTimeout(function(){
        let t = performance.timing
        console.log('DNS查询耗时 ：' + (t.domainLookupEnd - t.domainLookupStart).toFixed(0))
        console.log('TCP链接耗时 ：' + (t.connectEnd - t.connectStart).toFixed(0))
        console.log('request请求耗时 ：' + (t.responseEnd - t.responseStart).toFixed(0))
        console.log('解析dom树耗时 ：' + (t.domComplete - t.domInteractive).toFixed(0))
        console.log('白屏时间 ：' + (t.responseStart - t.navigationStart).toFixed(0))
        console.log('domready时间 ：' + (t.domContentLoadedEventEnd - t.navigationStart).toFixed(0))
        console.log('onload时间 ：' + (t.loadEventEnd - t.navigationStart).toFixed(0))

        if(t = performance.memory){
            console.log('js内存使用占比 ：' + (t.usedJSHeapSize / t.totalJSHeapSize * 100).toFixed(2) + '%')
        }
    })
}
```

**无阻塞**

写在HTML头部的JavaScript（无异步），和写在HTML标签中的Style会阻塞页面的渲染，因此CSS放在页面头部并使用Link方式引入，避免在HTML标签中写Style，JavaScript放在页面尾部或使用异步方式加载 css不会阻塞 style会阻塞

**6.4 GPU加速**

CSS中以下属性（CSS3 transitions、CSS3 3D transforms、Opacity、Canvas、WebGL、Video）来触发GPU渲染，请合理使用

**webpack**

**chunk可以是多个module 比如什么都没设置就所有模块都到index这个chunk里面**

![img](https://i.loli.net/2021/07/20/a5NeZdCmc2jxDnI.png)

- 一切源代码文件均可通过各种 Loader 转换为 JS 模块 （module），模块之间可以互相引用。
- webpack 通过入口点（entry point）递归处理各模块(module)引用关系，最后输出为一个或多个产物包 js(bundle) 文件。
- 每一个入口点都是一个块组（chunk group）每一个 chunk 都有对应的一个打包后的输出文件（asset/bundle）

**执行流程**

![img](https://i.loli.net/2021/07/20/RMNt1uKDzibkCq9.png)

**区别名称**

- Compiler：compiler对象是一个全局单例，他负责把控**整个webpack打包**的构建流程。在编译初始化阶段被创建的全局单例，包含完整配置信息、loaders、plugins以及各种工具方法
- Compilation：代表一次 webpack 构建和生成编译资源的的过程，在watch模式下**每一次文件**变更触发的重新编译都会生成新的 Compilation 对象，包含了当前编译的模块 module, 编译生成的资源，变化的文件, 依赖的状态等
- Compiler: 可以简单的理解为 Webpack 实例，它包含了当前 Webpack 中的所有**配置信息**，如 options， loaders, plugins 等信息，全局唯一，只在启动时完成初始化创建，随着生命周期逐一传递；

- Compilation: 可以称为 编译实例。当监听到文件发生改变时，Webpack 会创建一个新的 Compilation 对象，**开始一次新的编译**。它包含了当前的输入资源，输出资源，变化的文件等，**同时通过它提供的 api，可以监听每次编译过程中触发的事件钩子**；plugin可以触发钩子

- 而每个模块间的依赖关系，则依赖于AST语法树。每个模块文件在通过Loader解析完成之后，会通过acorn库生成模块代码的AST语法树，通过语法树就可以分析这个模块是否还有依赖的模块，进而继续循环执行下一个模块的编译解析。
- 最终Webpack打包出来的bundle文件是一个IIFE的执行函数。

**热更新**

- 当修改了一个或多个文件；
- 文件系统接收更改并通知 webpack；
- webpack 重新编译构建一个或多个模块，并通知 HMR 服务器进行更新；
- HMR Server 使用 webSocket 通知 HMR runtime 需要更新，HMR 运行时通过 HTTP 请求更新 jsonp
- HMR 运行时替换更新中的模块，如果确定这些模块无法更新，则触发整个页面刷新

**webpack工具分析**

- 准备基于时间的分析工具：我们需要一类插件，来帮助我们统计项目构建过程中在编译阶段的耗时情况。speed-measure-webpack-plugin 分析**插件加载的时间**
- 使用 webpack-bundle-analyzer **分析产物内容**

**code-spliting: 代码分割技术**，将代码分割成多份进行 懒加载 或 异步加载，避免打包成一份后导致体积过大，影响页面的首屏加载；

- Webpack 中使用 SplitChunksPlugin 进行拆分；
- 按 页面 拆分: 不同页面打包成不同的文件；
- 按 功能 拆分:
  - 将类似于播放器，计算库等大模块进行拆分后再**懒加载**引入；
  - 提取复用的业务代码，减少冗余代码；
- 按 文件修改频率 拆分: 将**第三方库**等不常修改的代码单独打包，**而且不改变其文件 hash** 值，能最大化运用浏览器的缓存；

**scope hoisting:** 作用域提升，将分散的模块划分到同一个作用域中，避免了代码的重复引入，有效减少打包后的代码体积和运行时的内存损耗；

![img](https://i.loli.net/2021/08/10/5kSQTIBXEoCUavZ.png)

hello这个变量就不用再去倒入文件啦直接一个作用域啦let hello

### 8 Webpack Proxy工作原理？为什么能解决跨域

\1. 是什么

webpack proxy，即webpack提供的代理服务

基本行为就是接收客户端发送的请求后转发给其他服务器

其目的是为了便于开发者在开发模式下解决跨域问题（浏览器安全策略限制）

想要实现代理首先需要一个**中间服务器**，webpack中提供服务器的工具为webpack-dev-server

\2. webpack-dev-server

webpack-dev-server是 webpack 官方推出的一款开发工具，将自动编译和自动刷新浏览器等一系列对开发友好的功能全部集成在了一起

目的是为了提高开发者日常的**开发效率**，「只适用在开发阶段」

```
module.exports = {
    // ...
    devServer: {
        contentBase: path.join(__dirname, 'dist'),
        compress: true,
        port: 9000,
        proxy: {
            '/api': {
                target: 'https://api.github.com'
            }
        }
        // ...
    }
}
```

\2. **工作原理**

proxy工作原理实质上是利用http-proxy-middleware 这个http代理中间件，实现请求转发给其他服务器

在开发阶段，本地地址为http://localhost:3000，该浏览器发送一个前缀带有/api标识的请求到服务端获取数据，但响应这个请求的服务器只是将请求转发到另一台服务器中

### 介绍一下 babel原理

babel 的编译过程分为三个阶段：parsing、transforming、generating，以 ES6 编译为 ES5 作为例子：

1. ES6 代码输入；
2. **babylon** 进行解析得到 AST； parsing
3. plugin 用 **babel-traverse** 对 AST树进行遍历编译，得到新的 AST树；transforming
4. 用 babel-**generator** 通过 AST树生成 ES5 代码。generating

**url**

![img](https://i.loli.net/2021/07/20/Gmkn7UPH4i1jbqK.png)



**1. 数据类型与编码**

- text：即文本格式的可读数据，我们最熟悉的应该就是 text/html 了，表示超文本文档，此外还有纯文本 text/plain、样式表 text/css 等。
- image：即图像文件，有 image/gif、image/jpeg、image/png 等。
- audio/video：音频和视频数据，例如 audio/mpeg、video/mp4 等。
- application：数据格式不固定，可能是文本也可能是二进制，必须由上层应用程序来解释。常见的有 application/json，application/javascript、application/pdf 等，另外，如果实在是不知道数据是什么类型，像刚才说的“黑盒”，就会是 application/octet-stream，即不透明的二进制数据

但仅有 MIME type 还不够，因为 HTTP 在传输时为了节约带宽，有时候还会压缩数据，为了不要让浏览器继续“猜”，还需要有一个“Encoding type”，告诉数据是用的什么编码格式，这样对方才能正确解压缩，还原出原始的数据。

**2. 数据类型使用的头字段**

有了 MIME type 和 Encoding type，无论是浏览器还是服务器就都可以轻松识别出 body 的类型，也就能够正确处理数据了。

HTTP 协议为此定义了两个 Accept 请求头字段和两个 Content 实体头字段，用于客户端和服务器进行“内容协商”。也就是说，客户端用 Accept 头告诉服务器希望接收什么样的数据，而服务器用 Content 头告诉客户端实际发送了什么样的数据

![img](https://i.loli.net/2021/07/20/r2pjG8OkNhZ4ibe.png)

Accept字段标记的是客户端可理解的 **MIME** **type**

\3. **语言类型使用的头字段**

```
Accept-Language: zh-CN, zh, en
```

相应的，服务器应该在响应报文里用头字段Content-Language告诉客户端实体数据使用的实际语言类型

```
Content-Language: zh-CN
```

- 字符集在 HTTP 里使用的请求头字段是Accept-Charset，但响应头里却没有对应的 Content-Charset，而是在Content-Type字段的数据类型后面用“charset=xxx”来表示，这点需要特别注意。
- Accept-Charset: gbk, utf-8 Content-Type: text/html; charset=utf-8

q=value表示希望收到的文件类型权重

Accept: text/html,application/xml;q=0.9,*/*;q=0.8

但有的时候，服务器会在响应头里多加一个Vary字段，记录服务器在内容协商时参考的请求头字段，给出一点信息

```
Vary: Accept-Encoding,User-Agent,Accept
```

**mime type 就是文件类型**

- 数据类型表示实体数据的内容是什么，使用的是 MIME type，相关的头字段是 Accept和 Content-Type；

**HTTP 缺点**

- 无状态，有时候，需要保存信息，比如像购物系统，需要保留下顾客信息等等，另外一方面，有时候，无状态也会减少网络开销，比如类似直播行业这样子等，这个还是分场景来说。
- 明文传输，即协议里的报文(主要指的是头部)不使用二进制数据，而是文本形式。这让HTTP的报文信息暴露给了外界，给攻击者带来了便利。
- 队头阻塞，当http开启长连接时，共用一个TCP连接，当某个请求时间过长时，其他的请求只能处于阻塞状态，这就是队头阻塞问题。

### 8 说一说HTTP 的请求方法

- HTTP1.0定义了三种请求方法： GET, POST 和 HEAD方法
- HTTP1.1新增了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT

http/1.1规定了以下请求方法(注意，都是大写):

- GET： 请求获取Request-URI所标识的资源
- POST： 在Request-URI所标识的资源后附加新的数据
- HEAD： 请求获取由Request-URI所标识的资源的**响应消息报头**
- PUT： 请求服务器存储一个资源，并用Request-URI作为其标识（修改数据）
- DELETE： 请求服务器删除对应所标识的资源
- TRACE： 请求服务器回送收到的请求信息，主要用于**测试或诊断**
- CONNECT： **建立连接隧道，用于代理服务器**
- OPTIONS： 列出可对资源实行的**请求方法**，用来跨域请求
- JS 的 XMLHttpRequest对象进行 CORS 跨域资源共享时，对于复杂请求，就是使用 OPTIONS 方法发送嗅探请求，以判断是否有对指定资源的访问权限。

### 9 谈一谈GET 和 POST 的区别

本质上，只是语义上的区别，GET 用于获取资源，POST 用于提交资源。

具体差别👇

- 从缓存角度看，GET 请求后**浏览器会主动缓存**，POST 默认情况下不能。
- 从参数角度来看，GET请求一般放在URL中，因此不安全，POST请求放在请求体中，相对而言较为安全，但是在抓包的情况下都是一样的。
- 从编码角度看，GET请求只能经行URL编码，**只能接受ASCII码**，而POST支持更多的**编码类型**且不对数据类型限值。
- GET请求幂等，POST请求不幂等，幂等指发送 M 和 N 次请求（两者不相同且都大于1），服务器上资源的状态一致。
- GET请求会一次性发送请求报文，POST请求通常分为**两个TCP数据包**，首先发 header 部分，如果服务器响应 100(continue)， 然后发 body 部分

### 10 谈一谈队头阻塞问题

什么是队头阻塞？

对于每一个HTTP请求而言，这些任务是会被放入一个**任务队列**中**串行执行**的，一旦队首任务请求太慢时，就会阻塞后面的请求处理，这就是HTTP队头阻塞问题。

**有什么解决办法吗** 都是增加多个任务队列

并发连接

我们知道对于一个域名而言，是允许分配多个长连接的，那么可以理解成增加了任务队列，也就是说不会导致一个任务阻塞了该任务队列的其他任务，在RFC规范中规定客户端最多并发2个连接，不过实际情况就是要比这个还要多，举个例子，Chrome中是6个。

域名分片

- 顾名思义，我们可以在一个域名下分出多个**二级域名**出来，而它们最终指向的还是同一个**服务器**，这样子的话就可以并发处理的任务队列更多，也更好的解决了队头阻塞的问题。
- 举个例子，比如TianTian.com，可以分出很多二级域名，比如Day1.TianTian.com，Day2.TianTian.com,Day3.TianTian.com,这样子就可以有效解决队头阻塞问题。

**11 谈一谈HTTP数据传输**

大概遇到的情况就分为定长数据 与 不定长数据的处理吧。

定长数据

对于定长的数据包而言，发送端在发送数据的过程中，需要设置Content-Length,来指明发送数据的长度。

当然了如果采用了Gzip压缩的话，Content-Length设置的就是压缩后的传输长度

- Content-Length如果存在并且有效的话，则必须和消息内容的传输长度完全一致，也就是说，如果过短就会截断，过长的话，就会导致超时。
- 在HTTP/1.1版本中，如果是Keep-alive的话，chunked优先级高于Content-Length

**不定长数据**



```
Transfer-Encoding: chunked
```

通过chunked机制，可以完成对不定长数据的处理，当然了，你需要知道的是

- 如果头部信息中有Transfer-Encoding,优先采用Transfer-Encoding里面的方法来找到对应的长度。
- 如果设置了Transfer-Encoding，那么Content-Length将被忽视。
- 使用长连接的话，会持续的推送动态内容。

### 13 介绍一下HTTPS和HTTP区别

HTTP + TLS/SSL

SSL

安全套接层（Secure Sockets Layer）

TLS

（传输层安全，Transport Layer Security）

![img](https://i.loli.net/2021/07/20/a5LqH7VGKQRbStr.png)

- HTTP 是明文传输协议，HTTPS 协议是由 SSL+HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。
- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO,谷歌、百度优先索引HTTPS网页。
- HTTPS标准端口443，HTTP标准端口80。
- HTTPS需要用到SSL证书，而HTTP不用。

我觉得记住以下两点HTTPS**主要作用**就行👇

1. 对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全;
2. 对网站服务器进行真实身份认证。

### 14 HTTPS握手过程

- 第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法
- 第二步，服务端确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数
- 第三步，客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务端
- 第四步，服务端使用自己的私钥，获取客户端发来的随机数（即Premaster secret）。
- 第五步，客户端和服务端根据约定的加密方法，使用前面的三个随机数，生成"对话密钥"（session key），用来加密接下来的整个对话过程

总结 随机数 公钥加密随机数 三个随机数加密文件

TLS/SSL 的功能实现主要依赖于三类基本算法：散列函数 、对称加密和非对称加密，其利用**非对称加密实现身份认证和密钥协商(随机数的产生)**，对称加密算法采用协商的密钥对**数据加密**，基于散列函数验证信息的完整性。

**1. 对称加密**

加密和解密用同一个秘钥的加密方式叫做对称加密，所以数据加密得对称加密

问题一: WWW万维网有许许多多的客户端，**不可能都用秘钥A**进行信息加密，这样子很不合理，所以解决办法就是使用一个客户端使用一个密钥进行加密。

问题二:既然不同的客户端使用**不同的密钥**，那么对称加密的**密钥如何传输**？ 那么解决的办法只能是一端生成一个秘钥，然后通过HTTP传输给另一端，那么这样子又会产生新的问题。

问题三: 这个传输密钥的过程，又如何保证加密？如果被中间人拦截，**密钥也会被获取**, 那么你会说对密钥再进行加密，那又怎么保存对密钥加密的过程，是加密的过程？

到这里，我们似乎想明白了，使用对称加密的方式，行不通，所以我们需要采用非对称加密

**2. 非对称加密**





### 谈一谈你对HTTP/2理解



- 提升访问速度(可以对于，请求资源所需时间更少，访问速度更快，相比 http1.0)
- 允许多路复用:多路复用允许同时通过单一的 HTTP/2 连接发送多重请求-响应信息。改 善了:在 http1.1 中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量限 制(连接数量)，超过限制会被阻塞
- 二进制分帧:HTTP2.0 会将所有的传输信息分割为更小的信息或者帧，并对他们进行二 进制编码
- 首部压缩
- 服务器端推送

**头部压缩**

HTTP 1.1版本会出现 User-Agent、Cookie、Accept、Server、Range 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。

HTTP 2.0 使用 HPACK 算法进行压

**多路复用**

- HTTP 1.x 中，如果想并发多个请求，必须使用多个 TCP 链接，且浏览器为了控制资源，还会对单个域名有 6-8个的TCP链接请求限制。

HTTP2中：

- 同域名下所有通信都在单个连接上完成

http1.x是改善啦每一次都得用http链接 但是请求还是穿行的 http2改善的是请求也是流水线一样并行的

**二进制分帧**

之前是明文传输，不方便计算机解析，对于回车换行符来说到底是内容还是分隔符，都需要内部状态机去识别，这样子效率低，HTTP/2采用二进制格式，全部传输01串，便于机器解码。

这样子一个报文格式就被拆分为一个个二进制帧，用Headers帧存放头部字段，Data帧存放请求体数据。这样子的话，**就是一堆乱序的二进制帧，它们不存在先后关系**，因此不需要排队等待，解决了HTTP队头阻塞问题。在链路上随机传输 最后根据id组装

在客户端与服务器之间，双方都可以互相发送二进制帧，这样子双向传输的序列，称为流，所以HTTP/2中以流来表示一个TCP连接上进行多个数据帧的通信，这就是多路复用概念。

那乱序的二进制帧，是如何组装成对于的报文呢？

- 所谓的乱序，值的是不同ID的Stream是乱序的，对于同一个Stream ID的帧是按顺序传输的。
- 接收方收到二进制帧后，**将相同的Stream ID组装成完整的请求报文和响应报文**。
- 二进制帧中有一些字段，控制着优先级和流量控制等功能，这样子的话，就可以设置数据帧的优先级，让服务器处理重要资源，优化用户体验。

**tcp缺点**

- TCP 以及 TCP+TLS建立连接的延时,HTTP/2使用TCP协议来传输的，而如果使用HTTPS的话，还需要使用TLS协议进行安全传输，而使用TLS也需要一个握手过程,在传输数据之前，导致我们需要花掉 3～4 个 RTT。
- TCP的队头阻塞并没有彻底解决。在HTTP/2中，多个请求是跑在一个TCP管道中的。但当HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求。

即建立链接时间长；队头阻塞

**18 HTTP3**

基于 **UDP** 协议的“QUIC”协议，让HTTP跑在QUIC上而不是TCP上。主要特性如下

- 实现了类似TCP的流量控制、传输可靠性的功能。虽然UDP不提供可靠性的传输，但QUIC在UDP的基础之上增加了一层来保证数据可靠性传输。它提供了数据包重传、拥塞控制以及其他一些TCP中存在的特性
- 实现了快速握手功能。由于QUIC是基于UDP的，所以QUIC可以实现使用0-RTT或者1-RTT来建立连接，解决tcp需要多个rtt来建立链接的问题
- 多路复用，彻底解决TCP中队头阻塞的问题。

**总结http**

- HTTP 0.9：1991年,原型版本，功能简陋，只有一个命令GET,只支持纯文本内容，该版本已过时。
- HTTP 1.0
  - 任何格式的内容都可以发送，这使得互联网不仅可以传输文字，还能传输图像、视频、二进制等文件。
  - 除了**GET命令，还引入了POST命令和HEAD命令**。
  - http请求和回应的格式改变，除了数据部分，每次通信都必须包括头信息（HTTP header），用来描述一些元数据。
  - 只使用 header **中的 If-Modified-Since 和 Expires 作**为缓存失效的标准。
  - 不支持断点续传，也就是说，每次都会传送全部的页面和数据。
  - 通常每台计算机只能绑定一个 IP，所以请求消息中的 URL 并没有传递主机名（hostname）
- HTTP 1.1 http1.1是目前最为主流的http协议版本，从1999年发布至今，仍是主流的http协议版本。
  - 引入了持久连接（ persistent connection），即TCP连接默认不关闭，可以被多个请求复用，不用声明**Connection: keep-alive**。长连接的连接时长可以通过请求头中的 keep-alive 来设置
  - 引入了管道机制（ pipelining），即在同一个TCP连接里，客户端可以同时发送多个 请求，进一步改进了HTTP协议的效率。
  - HTTP 1.1 中新增加了 **E-tag，If-Unmodified-Since, If-Match, If-None-Match** 等缓存控制标头来控制缓存失效。
  - 支持断点续传，通过使用请求头中的 Range 来实现。
  - 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。
  - 新增方法：**PUT、 PATCH、 OPTIONS、 DELETE。**
- http1.x版本问题
  - 在传输数据过程中，所有内容都**是明文**，客户端和服务器端都无法验证对方的身份，无法保证数据的安全性。
  - HTTP/1.1 版本默认允许复用TCP连接，但是在同一个TCP连接里，所有数据通信是按次序进行的，服务器通常在处理完一个回应后，才会继续去处理下一个，这样子就会造成**队头阻塞**。
  - http/1.x 版本支持Keep-alive，用此方案来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，Keep-alive会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。
- HTTP 2.0
  - 二进制分帧 这是一次彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"：头信息帧和数据帧。
  - 头部压缩 HTTP 1.1版本会出现 User-Agent、Cookie、Accept、Server、Range 等字段可能会占用几百甚至几千字节，而 Body 却经常只有几十字节，所以导致头部偏重。HTTP 2.0 使用 HPACK 算法进行压缩。
  - 多路复用 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题。
  - 服务器推送 允许服务器未经请求，主动向客户端发送资源，即服务器推送。
  - 请求优先级 可以设置数据帧的优先级，让服务端先处理重要资源，优化用户体验。

**dns缓存**

- 本地客户端向服务器发起请求查询 IP 地址
- 查看浏览器有没有该域名的 IP 缓存
- 查看操作系统有没有该域名的 IP 缓存
- 查看 Host 文件有没有该域名的解析配置
- 本地dns服务器有没有缓存

缓存也很好理解，在一个请求中，当某个DNS服务器收到一个DNS回答后，它能够回答中的信息缓存在本地存储器中。返回的资源记录中的 TTL 代表了该条记录的缓存的时间。

**DNS实现负载平衡**



原因： 这是因为一般的大型网站使用多台服务器提供服务，**因此一个域名可能会对应 多个服务器地址。**

举个例子来说👇

- 当用户发起网站域名的 DNS 请求的时候，DNS 服务器返回这个域名所对应的服务器 IP 地址的集合
- 在每个回答中，会循环这些 IP 地址的顺序，用户一般会选择排在前面的地址发送请求。
- 以此将用户的请求均衡的分配到各个不同的服务器上，这样来实现负载均衡。

**DNS 为什么使用 UDP 协议作为传输层协议？**

DNS 使用 UDP 协议作为传输层协议的主要原因是为了避免使用 TCP 协议时造成的**连接时延**

- 为了得到一个域名的 IP 地址，往往会向多个域名服务器查询，如果使用 TCP 协议，那么每次请求都会存在连接时延，这样使 DNS 服务变得很慢。
- 大多数的地址查询请求，都是浏览器请求页面时发出的，这样会造成网页的等待时间过长

**查询过程**，本地查询是递归查询，依次通过浏览器缓存 —>> 本地hosts文件 —>> 本地DNS解析器 —>>本地DNS服务器 —>> 其他域名服务器请求。 **既有本地dns解析器又有服务器**

### 21 短轮询、长轮询和 WebSocket 间的区别

\1. 短轮询

浏览器每隔一段时间向浏览器发送 http 请求，服务器端

\2. 长轮询

当服务器收到客户端发来的请求后，服务器端不会直接进行响应，而是先将 这个请求挂起，然后判断服务器端数据是否有更新。如果有更新，则进行响应，如果一直没有数据，则到达一定的时间限制才返回

\3. WebSocket

该协议允许由服务器主动的向客户端推送信息。

### 22 说一说正向代理和反向代理

正向代理

我们**常说的代理**也就是指正向代理，正向代理的过程，它隐藏了真实的请求客户端，服务端不知道真实的客户端是谁，客户端请求的服务都被代理服务器代替来请求

http-proxy 转发请求

反向代理

这种代理模式下，它隐藏了真实的服务端，当我们向一个网站发起请求的时候，背后可能有成千上万台服务器为我们服务，具体是哪一台，我们不清楚，一般而言反向代理服务器一般用来实现**负载平衡**

**负载平衡的两种实现方式？**

- 一种是使用反向代理的方式，用户的请求都发送到反向代理服务上，然后由反向代理服务器来转发请求到真实的服务器上，以此来实现集群的负载平衡。
- 另一种是 DNS 的方式，DNS 可以用于在冗余的服务器上实现负载平衡。DNS返回多个ip地址

**为什么有websocket协议**

**为了解决http的半双工的方式**

然后来的 HTTP/2、HTTP/3 新增了 Stream、Server Push 等特性，但“请求 - 应答”依然是主要的工作方式。这就导致 HTTP 难以应用在动态页面、即时消息、网络游戏等要求“实时通信”的领域。

请求 - 应答”是一种“半双工”的通信模式，虽然可以双向收发数据，但同一时刻只能一个方向上有动作，传输效率低。更关键的一点，它是一种“被动”通信模式，服务器只能“被动”响应客户端的请求，无法主动向客户端发送数据。

- 服务发现方面，WebSocket 没有使用 TCP 的“IP 地址 + 端口号”，而是延用了 HTTP 的 URI 格式，但开头的协议名不是“http”，引入的是两个新的名字：“ws”和“wss”，分别表示明文和加密的 WebSocket 协议。